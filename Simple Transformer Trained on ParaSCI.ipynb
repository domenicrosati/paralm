{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feabd425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ParaSCI' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/dqxiu/ParaSCI.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e59f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas torch transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0c542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4095c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74210701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
    "                 nlayers: int, dropout: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, d_model)\n",
    "        self.d_model = d_model\n",
    "        self.decoder = nn.Linear(d_model, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src: Tensor, shape [seq_len, batch_size]\n",
    "            src_mask: Tensor, shape [seq_len, seq_len]\n",
    "\n",
    "        Returns:\n",
    "            output Tensor of shape [seq_len, batch_size, ntoken]\n",
    "        \"\"\"\n",
    "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
    "        \n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src)\n",
    "        output = self.decoder(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90915d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Tensor, shape [seq_len, batch_size, embedding_dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57684719",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "with open('./ParaSCI/Data/ParaSCI-ACL/train/train.src') as file:\n",
    "    train_source = file.readlines()\n",
    "\n",
    "with open('./ParaSCI/Data/ParaSCI-ACL/train/train.tgt') as file:\n",
    "    train_target = file.readlines()\n",
    "    \n",
    "with open('./ParaSCI/Data/ParaSCI-ACL/test/test.src') as file:\n",
    "    test_source = file.readlines()\n",
    "\n",
    "with open('./ParaSCI/Data/ParaSCI-ACL/test/test.tgt') as file:\n",
    "    test_target = file.readlines()\n",
    "    \n",
    "with open('./ParaSCI/Data/ParaSCI-ACL/val/val.src') as file:\n",
    "    val_source = file.readlines()\n",
    "\n",
    "with open('./ParaSCI/Data/ParaSCI-ACL/val/val.tgt') as file:\n",
    "    val_target = file.readlines()\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = build_vocab_from_iterator(map(tokenizer, train_source+train_target+test_source+test_target+val_source+val_target))\n",
    "\n",
    "from datasets import Dataset, DatasetDict, load_metric\n",
    "import numpy as np\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    'id': np.arange(len(train_source)),\n",
    "    'paraphrase': [{'input': data[0], 'output': data[1]} for data in zip(train_source, train_target)],\n",
    "})\n",
    "test_dataset = Dataset.from_dict({\n",
    "        'id': np.arange(len(test_source)),\n",
    "    'paraphrase': [{'input': data[0], 'output': data[1]} for data in zip(test_source, test_target)],\n",
    "})\n",
    "val_dataset = Dataset.from_dict({\n",
    "    'id': np.arange(len(val_source)),\n",
    "    'paraphrase': [{'input': data[0], 'output': data[1]} for data in zip(val_source, val_target)]\n",
    "})\n",
    "raw_dataset = DatasetDict()\n",
    "raw_dataset['train'] = train_dataset\n",
    "raw_dataset['test'] = test_dataset\n",
    "raw_dataset['val'] = val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19974df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('t5-base', return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bd876859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0cd9facd0349fe8342e980d40dba37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b4be3d1a003499eb431820f233fe9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a412fda6db14d0d81b39047fb00a975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_input_length = 64\n",
    "max_target_length = 64\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[\"input\"] for ex in examples[\"paraphrase\"]]\n",
    "    targets = [ex[\"output\"] for ex in examples[\"paraphrase\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    # Set up the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True, padding=\"max_length\")\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tokenized_datasets = raw_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    remove_columns=raw_dataset[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "03adab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntokens = tokenizer.vocab_size  # size of vocabulary\n",
    "emsize = 200  # embedding dimension\n",
    "d_hid = 200  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "nhead = 2  # number of heads in nn.MultiheadAttention\n",
    "dropout = 0.2  # dropout probability\n",
    "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1433f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollator\n",
    "\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a23807d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=tokenized_datasets['train'],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6890ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=tokenized_datasets['test'],\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "34855204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0  # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
    "num_batches = len(train_dataloader) / batch_size\n",
    "def train(model: nn.Module) -> None:\n",
    "    model.train()  # turn on train mode\n",
    "    total_loss = 0.\n",
    "    log_interval = 20\n",
    "    start_time = time.time()\n",
    "\n",
    "    for i,batch in tqdm(enumerate(train_dataloader)):\n",
    "        sources, mask, targets = batch['input_ids'], batch['attention_mask'], batch['labels']\n",
    "        output = model(torch.stack(sources), torch.stack(mask))\n",
    "        loss = criterion(output.view(-1, ntokens), torch.stack(targets).view(-1))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
    "            cur_loss = total_loss / log_interval\n",
    "            ppl = cur_loss\n",
    "            print(f'| epoch {epoch} | {i}/{num_batches} batches | '\n",
    "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
    "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n",
    "\n",
    "def evaluate(model: nn.Module) -> float:\n",
    "    model.eval()  # turn on evaluation mode\n",
    "    total_loss = 0.\n",
    "    with torch.no_grad():\n",
    "        for i,batch in tqdm(enumerate(test_dataloader)):\n",
    "            sources, mask, targets = torch.stack(batch['input_ids']), torch.stack(batch['attention_mask']), torch.stack(batch['labels'])\n",
    "            output = model(sources, mask)\n",
    "            output_flat = output.view(-1, ntokens)\n",
    "            total_loss += batch_size * criterion(output_flat, targets.view(-1)).item()\n",
    "    return total_loss / (len(test_dataloader) - 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9e14e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [08:06, 21.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | 20/0.111328125 batches | lr 1.79 | ms/batch 24333.47 | loss  2.69 | ppl     2.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [15:30, 21.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | 40/0.111328125 batches | lr 1.79 | ms/batch 22172.27 | loss  2.53 | ppl     2.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [20:56, 22.04s/it]\n",
      "5it [00:31,  6.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 1 | time: 1288.10s | valid loss 1787.97 | valid ppl  1787.97\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [17:31, 23.32s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 2 | 20/0.111328125 batches | lr 1.70 | ms/batch 52587.18 | loss  2.65 | ppl     2.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [38:55, 21.75s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 2 | 40/0.111328125 batches | lr 1.70 | ms/batch 64168.70 | loss  2.53 | ppl     2.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [44:26, 46.79s/it]\n",
      "5it [00:35,  7.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 2 | time: 2703.12s | valid loss 1779.74 | valid ppl  1779.74\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [07:40, 21.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 3 | 20/0.111328125 batches | lr 1.62 | ms/batch 23025.37 | loss  2.61 | ppl     2.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [14:59, 21.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 3 | 40/0.111328125 batches | lr 1.62 | ms/batch 21945.72 | loss  2.50 | ppl     2.50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [20:39, 21.74s/it]\n",
      "5it [00:33,  6.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 3 | time: 1272.69s | valid loss 1771.52 | valid ppl  1771.52\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [07:34, 21.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 4 | 20/0.111328125 batches | lr 1.54 | ms/batch 22702.77 | loss  2.61 | ppl     2.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [14:58, 22.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 4 | 40/0.111328125 batches | lr 1.54 | ms/batch 22224.24 | loss  2.49 | ppl     2.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [20:40, 21.76s/it]\n",
      "5it [00:38,  7.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 4 | time: 1279.15s | valid loss 1750.70 | valid ppl  1750.70\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [07:50, 22.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 5 | 20/0.111328125 batches | lr 1.46 | ms/batch 23529.50 | loss  2.60 | ppl     2.60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [15:12, 22.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 5 | 40/0.111328125 batches | lr 1.46 | ms/batch 22117.70 | loss  2.47 | ppl     2.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [20:56, 22.04s/it]\n",
      "5it [00:34,  6.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 5 | time: 1290.62s | valid loss 1752.40 | valid ppl  1752.40\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [07:55, 22.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 6 | 20/0.111328125 batches | lr 1.39 | ms/batch 23764.15 | loss  2.57 | ppl     2.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [15:38, 22.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 6 | 40/0.111328125 batches | lr 1.39 | ms/batch 23170.19 | loss  2.47 | ppl     2.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [21:26, 22.57s/it]\n",
      "5it [00:36,  7.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 6 | time: 1323.47s | valid loss 1754.74 | valid ppl  1754.74\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [07:56, 22.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 7 | 20/0.111328125 batches | lr 1.32 | ms/batch 23833.43 | loss  2.57 | ppl     2.57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [17:24, 26.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 7 | 40/0.111328125 batches | lr 1.32 | ms/batch 28386.24 | loss  2.45 | ppl     2.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [23:02, 24.25s/it]\n",
      "5it [00:33,  6.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 7 | time: 1415.54s | valid loss 1730.45 | valid ppl  1730.45\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [39:14, 69.04s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 8 | 20/0.111328125 batches | lr 1.25 | ms/batch 117724.03 | loss  2.56 | ppl     2.56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [1:34:06, 497.56s/it]"
     ]
    }
   ],
   "source": [
    "best_val_loss = float('inf')\n",
    "epochs = 20\n",
    "best_model = None\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(model)\n",
    "    val_loss = evaluate(model)\n",
    "    val_ppl = val_loss\n",
    "    elapsed = time.time() - epoch_start_time\n",
    "    print('-' * 89)\n",
    "    print(f'| end of epoch {epoch} | time: {elapsed:5.2f}s | '\n",
    "          f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
    "    print('-' * 89)\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model)\n",
    "\n",
    "    scheduler.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca655293",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = evaluate(best_model)\n",
    "test_ppl = test_loss\n",
    "print('=' * 89)\n",
    "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
    "      f'test ppl {test_ppl:8.2f}')\n",
    "print('=' * 89)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35be2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tokenizer('foobarbazbub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0ccbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = best_model(torch.tensor(inp['input_ids']).unsqueeze(0), torch.tensor(inp['attention_mask']).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4bf91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(out.argmax(dim=2).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501cc74d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
